{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# später anpassen für colab und lokal\n",
    "\n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "class ConfigurableDataModule(LightningDataModule):\n",
    "    \"\"\"Class wraper für mit austauschbaren transforms\"\"\"\n",
    "    def __init__(self, data_dir: str, batch_size: int, transform):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Erstellen des Datensatzes als Instanz von ImageFolder\n",
    "        full_dataset = ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        # Setzen der Trainingsset/Validierungsset Größe\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        # Zufälliges aufteilen in Training- und Validierungdatensatz\n",
    "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Setzen des Traindataloader\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Setzen des Validation Dataloader\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanMetric\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "class BaseWasteClassifier(pl.LightningModule):\n",
    "    CLASS_NAMES = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
    "\n",
    "    def __init__(self, num_classes: int, results_dir=\"results\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # Get the class name of the model instance\n",
    "        model_class_name = self.__class__.__name__\n",
    "        # Initialize paths\n",
    "        self.results_dir = Path(results_dir) / model_class_name\n",
    "        self.models_dir = self.results_dir / \"models\"\n",
    "        self.images_dir = self.results_dir / \"images\"\n",
    "        self.plots_dir = self.results_dir / \"plots\"\n",
    "\n",
    "        # Create directories if they don't exist\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.models_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Placeholder for the actual model\n",
    "        self.model = None\n",
    "\n",
    "        # Initialize metrics\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='macro')\n",
    "        self.precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "        self.recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "        self.f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "\n",
    "        # Initialize metrics for average loss\n",
    "        self.train_loss_metric = torchmetrics.MeanMetric()\n",
    "        self.val_loss_metric = torchmetrics.MeanMetric()\n",
    "        # Initialize metrics for averaging\n",
    "        self.avg_train_losses = []\n",
    "        self.avg_val_losses = []\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
    "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
    "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
    "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        # Log precision, recall, and F1 Score\n",
    "        self.log('train_precision', precision, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_recall', recall, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.train_loss_metric(loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        avg_train_loss = self.train_loss_metric.compute()\n",
    "        self.log('epoch_avg_train_loss', avg_train_loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.avg_train_losses.append(avg_train_loss.item())\n",
    "        self.train_loss_metric.reset()\n",
    "\n",
    "    def on_validation_start(self):\n",
    "        self.clear_images_directory()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        start_time = time.perf_counter()  # Start timing for inference speed\n",
    "        \n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
    "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
    "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
    "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
    "        \n",
    "        inference_time = time.perf_counter() - start_time  # Stop timing for inference speed\n",
    "        self.log('val_inference_time', inference_time, prog_bar=True, logger=True)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        # Log precision, recall, and F1 Score\n",
    "        self.log('val_precision', precision, prog_bar=True)\n",
    "        self.log('val_recall', recall, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)  # Convert logits to predicted class indices\n",
    "\n",
    "        if random.random() < 0.1:  # Log images randomly\n",
    "            self.log_images_with_labels(x, y, predictions, batch_idx)\n",
    "        \n",
    "        self.val_loss_metric(loss)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Compute the average losses for the current epoch\n",
    "        avg_val_loss = self.val_loss_metric.compute()\n",
    "\n",
    "        # Log the average losses\n",
    "        self.log('epoch_avg_val_loss', avg_val_loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # Append the average losses to the lists for plotting\n",
    "        self.avg_val_losses.append(avg_val_loss.item())\n",
    "\n",
    "        # Reset the metrics for the next epoch\n",
    "        self.val_loss_metric.reset()\n",
    "\n",
    "        # Plot and save the loss curves\n",
    "        self.plot_and_save_loss_curves()\n",
    "\n",
    "\n",
    "    def log_images_with_labels(self, images, labels, predictions, batch_idx):\n",
    "        \"\"\"Save a batch of images with their actual and predicted labels, organized by class name and model class.\"\"\"\n",
    "        annotated_images = []\n",
    "        for i, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "            # Unnormalize the image for visualization\n",
    "            image = self.unnormalize(image)  # Make sure to call with self if it's an instance method\n",
    "            # Determine class name for the actual label\n",
    "            actual_class_name = self.CLASS_NAMES[label.item()]\n",
    "\n",
    "            # Ensure the class-specific directory exists within the model class directory\n",
    "            image_dir = self.images_dir / actual_class_name\n",
    "            image_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Convert to PIL Image for easy manipulation\n",
    "            pil_img = F.to_pil_image(image)\n",
    "\n",
    "            # Annotate image with actual and predicted labels\n",
    "            draw = ImageDraw.Draw(pil_img)\n",
    "            annotation_text = f'Actual: {actual_class_name}, Predicted: {self.CLASS_NAMES[prediction.item()]}'\n",
    "            draw.text((10, 10), annotation_text, fill=\"white\")\n",
    "\n",
    "            # Define the file path for saving the image within the specific class directory\n",
    "            file_path = image_dir / f\"epoch_{self.current_epoch}_batch_{batch_idx}_image_{i}.png\"\n",
    "\n",
    "            # Save the annotated image\n",
    "            pil_img.save(file_path)\n",
    "\n",
    "            # Convert back to tensor and add to list\n",
    "            annotated_img = to_tensor(pil_img)\n",
    "            annotated_images.append(annotated_img.unsqueeze(0))  # Add batch dimension\n",
    "\n",
    "        # Stack all annotated images into a single tensor for logging\n",
    "        annotated_images_tensor = torch.cat(annotated_images, dim=0)\n",
    "        img_grid = torchvision.utils.make_grid(annotated_images_tensor, nrow=4)\n",
    "\n",
    "        # Log the grid of annotated images\n",
    "        self.logger.experiment.add_image(f'Validation Images, Batch {batch_idx}', img_grid, self.current_epoch)\n",
    "\n",
    "    def clear_images_directory(self):\n",
    "        if self.images_dir.exists() and self.images_dir.is_dir():\n",
    "            for class_dir in self.images_dir.iterdir():\n",
    "                if class_dir.is_dir():  # Ensure it's a directory\n",
    "                    shutil.rmtree(class_dir)  # Delete the directory and all its contents  \n",
    "    \n",
    "    def plot_and_save_loss_curves(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(len(self.avg_train_losses)), self.avg_train_losses, label='Average Training Loss')\n",
    "        plt.plot(range(len(self.avg_val_losses)), self.avg_val_losses, label='Average Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Average Training and Validation Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plot_path = self.plots_dir / \"average_loss_curves.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "    def unnormalize(self, image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        \"\"\"Revert normalization of an image tensor.\"\"\"\n",
    "        image = image.clone()  # Clone the tensor to avoid in-place operations\n",
    "        for t, m, s in zip(image, mean, std):\n",
    "            t.mul_(s).add_(m)  # Multiply by std and add mean\n",
    "        return image\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Subclasses can override this if needed\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "def train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"model_logs\", callbacks=[]):\n",
    "    # Configure the ModelCheckpoint callback\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=model.models_dir,\n",
    "        filename='{epoch}-{val_loss:.2f}',\n",
    "        save_top_k=2,  # Save only the best checkpoint\n",
    "        verbose=True,\n",
    "        monitor='val_loss',  # Monitor validation loss (change to val_acc or any other metric as needed)\n",
    "        mode='min',  # 'min' for loss (use 'max' for accuracy)\n",
    "    )\n",
    "    callbacks.append(checkpoint_callback)\n",
    "    # Starten das Trainingsprozesses\n",
    "    logger = TensorBoardLogger(log_dir, name=logger_name)\n",
    "    trainer = Trainer(max_epochs=max_epochs, logger=logger, callbacks=callbacks)\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(BaseWasteClassifier):\n",
    "    def __init__(self, num_classes=9, lr=1e-3):\n",
    "        self.lr = 1e-3\n",
    "        super().__init__(num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 512),  # Bestätigt, dass dies für eine Eingabegröße von 224x224 korrekt ist\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # Overfitting vermeiden\n",
    "            nn.Linear(512, num_classes) # lineare Schicht auf die Klassen\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=tb_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Definiere die Transformationspipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Skaliere alle Bilder auf 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
    "\n",
    "callbacks = [\n",
    "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
    "        mode=\"max\",  # Maximiert die Genauigkeit\n",
    "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
    "    )\n",
    "]\n",
    "model = SimpleCNN(num_classes=9, lr=1e-3)\n",
    "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"simple_CNN\", callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3\n",
    "\n",
    "class InceptionWasteClassifier(BaseWasteClassifier):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__(num_classes)\n",
    "        self.model = inception_v3(weights=\"Inception_V3_Weights.DEFAULT\")\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            outputs = self.model(x)\n",
    "            return outputs.logits, outputs.aux_logits\n",
    "        else:\n",
    "            return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        outputs = self(x)  # This could be either a tensor or a tuple of tensors\n",
    "        logits = outputs if isinstance(outputs, torch.Tensor) else outputs[0]  # Select logits\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import InterpolationMode\n",
    "# Define the transformations as per Inception V3's requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(342, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\Felix\\Desktop\\RealWaste\\results\\InceptionWasteClassifier\\models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | accuracy          | MulticlassAccuracy  | 0     \n",
      "1 | precision         | MulticlassPrecision | 0     \n",
      "2 | recall            | MulticlassRecall    | 0     \n",
      "3 | f1_score          | MulticlassF1Score   | 0     \n",
      "4 | train_loss_metric | MeanMetric          | 0     \n",
      "5 | val_loss_metric   | MeanMetric          | 0     \n",
      "6 | model             | Inception3          | 25.1 M\n",
      "----------------------------------------------------------\n",
      "25.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.1 M    Total params\n",
      "100.523   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 119/119 [01:25<00:00,  1.40it/s, v_num=1, train_loss_step=1.030, train_acc_step=0.507, val_inference_time=0.100, val_loss=0.849, val_acc=0.744, val_precision=0.803, val_recall=0.776, val_f1=0.768, epoch_avg_val_loss=0.849, train_loss_epoch=1.570, train_acc_epoch=0.441]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric MeanMetric was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
      "Epoch 0, global step 119: 'val_loss' reached 0.84873 (best 0.84873), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\InceptionWasteClassifier\\\\models\\\\epoch=0-val_loss=0.85.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/119 [00:00<?, ?it/s, v_num=1, train_loss_step=1.030, train_acc_step=0.507, val_inference_time=0.100, val_loss=0.849, val_acc=0.744, val_precision=0.803, val_recall=0.776, val_f1=0.768, epoch_avg_val_loss=0.849, train_loss_epoch=1.570, train_acc_epoch=0.441]          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001E6D05779C0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1437, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
    "\n",
    "callbacks = [\n",
    "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
    "        mode=\"max\",  # Maximiert die Genauigkeit\n",
    "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
    "    )\n",
    "]\n",
    "model = InceptionWasteClassifier(num_classes=9)\n",
    "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"inceptionv3\", callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import densenet201\n",
    "\n",
    "class DenseNet201Classifier(BaseWasteClassifier):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__(num_classes)\n",
    "        self.model = densenet201(weights=\"DenseNet201_Weights.DEFAULT\")\n",
    "        self.model.classifier = torch.nn.Linear(self.model.classifier.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import InterpolationMode\n",
    "# Define the transformations as per Inception V3's requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\Felix\\Desktop\\RealWaste\\results\\DenseNet201Classifier\\models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | accuracy          | MulticlassAccuracy  | 0     \n",
      "1 | precision         | MulticlassPrecision | 0     \n",
      "2 | recall            | MulticlassRecall    | 0     \n",
      "3 | f1_score          | MulticlassF1Score   | 0     \n",
      "4 | train_loss_metric | MeanMetric          | 0     \n",
      "5 | val_loss_metric   | MeanMetric          | 0     \n",
      "6 | model             | DenseNet            | 18.1 M\n",
      "----------------------------------------------------------\n",
      "18.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 M    Total params\n",
      "72.441    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|▎         | 3/119 [00:31<20:27,  0.09it/s, v_num=6, train_loss_step=2.260, train_acc_step=0.180, train_precision_step=0.215, train_recall_step=0.125, train_f1_step=0.122]  "
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
    "\n",
    "callbacks = [\n",
    "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
    "        mode=\"max\",  # Maximiert die Genauigkeit\n",
    "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
    "    )\n",
    "]\n",
    "model = DenseNet201Classifier(num_classes=9)\n",
    "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"densenet201\", callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "\n",
    "class ResNet50Classifier(BaseWasteClassifier):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__(num_classes)\n",
    "        self.model = resnet50(weights=\"ResNet50_Weights.DEFAULT\")\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\Felix/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:03<00:00, 33.4MB/s]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\Felix\\Desktop\\RealWaste\\results\\ResNet50Classifier\\models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | accuracy          | MulticlassAccuracy  | 0     \n",
      "1 | precision         | MulticlassPrecision | 0     \n",
      "2 | recall            | MulticlassRecall    | 0     \n",
      "3 | f1_score          | MulticlassF1Score   | 0     \n",
      "4 | train_loss_metric | MeanMetric          | 0     \n",
      "5 | val_loss_metric   | MeanMetric          | 0     \n",
      "6 | model             | ResNet              | 23.5 M\n",
      "----------------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.106    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 119/119 [01:14<00:00,  1.59it/s, v_num=2, train_loss_step=1.320, train_acc_step=0.497, train_precision_step=0.723, train_recall_step=0.600, train_f1_step=0.640, val_inference_time=0.0874, val_loss=1.190, val_acc=0.672, val_precision=0.729, val_recall=0.697, val_f1=0.672, epoch_avg_val_loss=1.190, train_loss_epoch=1.730, train_acc_epoch=0.390, train_precision_epoch=0.451, train_recall_epoch=0.445, train_f1_epoch=0.396]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 119: 'val_loss' reached 1.18902 (best 1.18902), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=0-val_loss=1.19.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 119/119 [01:48<00:00,  1.10it/s, v_num=2, train_loss_step=0.820, train_acc_step=0.704, train_precision_step=0.780, train_recall_step=0.680, train_f1_step=0.694, val_inference_time=0.0785, val_loss=0.669, val_acc=0.789, val_precision=0.839, val_recall=0.793, val_f1=0.790, epoch_avg_val_loss=0.672, train_loss_epoch=0.882, train_acc_epoch=0.738, train_precision_epoch=0.799, train_recall_epoch=0.749, train_f1_epoch=0.745, epoch_avg_train_loss=1.730]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 238: 'val_loss' reached 0.66946 (best 0.66946), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=1-val_loss=0.67.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 119/119 [01:51<00:00,  1.06it/s, v_num=2, train_loss_step=0.527, train_acc_step=0.875, train_precision_step=0.903, train_recall_step=0.840, train_f1_step=0.855, val_inference_time=0.0819, val_loss=0.487, val_acc=0.830, val_precision=0.875, val_recall=0.838, val_f1=0.839, epoch_avg_val_loss=0.490, train_loss_epoch=0.526, train_acc_epoch=0.843, train_precision_epoch=0.881, train_recall_epoch=0.845, train_f1_epoch=0.847, epoch_avg_train_loss=0.881]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 357: 'val_loss' reached 0.48689 (best 0.48689), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=2-val_loss=0.49.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 119/119 [01:41<00:00,  1.18it/s, v_num=2, train_loss_step=0.304, train_acc_step=0.824, train_precision_step=0.938, train_recall_step=0.880, train_f1_step=0.894, val_inference_time=0.0746, val_loss=0.409, val_acc=0.860, val_precision=0.897, val_recall=0.863, val_f1=0.865, epoch_avg_val_loss=0.412, train_loss_epoch=0.353, train_acc_epoch=0.886, train_precision_epoch=0.921, train_recall_epoch=0.894, train_f1_epoch=0.896, epoch_avg_train_loss=0.526]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 476: 'val_loss' reached 0.40861 (best 0.40861), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=3-val_loss=0.41.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 119/119 [01:49<00:00,  1.08it/s, v_num=2, train_loss_step=0.143, train_acc_step=0.975, train_precision_step=0.973, train_recall_step=0.960, train_f1_step=0.962, val_inference_time=0.0917, val_loss=0.369, val_acc=0.880, val_precision=0.914, val_recall=0.882, val_f1=0.883, epoch_avg_val_loss=0.372, train_loss_epoch=0.257, train_acc_epoch=0.926, train_precision_epoch=0.944, train_recall_epoch=0.926, train_f1_epoch=0.927, epoch_avg_train_loss=0.353]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 595: 'val_loss' reached 0.36919 (best 0.36919), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=4-val_loss=0.37.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 119/119 [01:45<00:00,  1.13it/s, v_num=2, train_loss_step=0.216, train_acc_step=0.963, train_precision_step=0.960, train_recall_step=0.920, train_f1_step=0.925, val_inference_time=0.0723, val_loss=0.330, val_acc=0.888, val_precision=0.915, val_recall=0.891, val_f1=0.892, epoch_avg_val_loss=0.332, train_loss_epoch=0.182, train_acc_epoch=0.951, train_precision_epoch=0.968, train_recall_epoch=0.953, train_f1_epoch=0.955, epoch_avg_train_loss=0.257] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 714: 'val_loss' reached 0.33008 (best 0.33008), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=5-val_loss=0.33.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 119/119 [01:41<00:00,  1.17it/s, v_num=2, train_loss_step=0.253, train_acc_step=0.805, train_precision_step=0.948, train_recall_step=0.880, train_f1_step=0.903, val_inference_time=0.0601, val_loss=0.326, val_acc=0.892, val_precision=0.921, val_recall=0.893, val_f1=0.895, epoch_avg_val_loss=0.327, train_loss_epoch=0.134, train_acc_epoch=0.964, train_precision_epoch=0.980, train_recall_epoch=0.968, train_f1_epoch=0.970, epoch_avg_train_loss=0.182] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 833: 'val_loss' reached 0.32555 (best 0.32555), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=6-val_loss=0.33.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 119/119 [01:49<00:00,  1.09it/s, v_num=2, train_loss_step=0.0475, train_acc_step=1.000, train_precision_step=1.000, train_recall_step=1.000, train_f1_step=1.000, val_inference_time=0.0691, val_loss=0.311, val_acc=0.898, val_precision=0.918, val_recall=0.898, val_f1=0.898, epoch_avg_val_loss=0.313, train_loss_epoch=0.0952, train_acc_epoch=0.981, train_precision_epoch=0.988, train_recall_epoch=0.983, train_f1_epoch=0.983, epoch_avg_train_loss=0.134]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 952: 'val_loss' reached 0.31137 (best 0.31137), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=7-val_loss=0.31.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 119/119 [01:49<00:00,  1.09it/s, v_num=2, train_loss_step=0.0202, train_acc_step=1.000, train_precision_step=1.000, train_recall_step=1.000, train_f1_step=1.000, val_inference_time=0.0707, val_loss=0.300, val_acc=0.896, val_precision=0.922, val_recall=0.898, val_f1=0.899, epoch_avg_val_loss=0.302, train_loss_epoch=0.0718, train_acc_epoch=0.989, train_precision_epoch=0.993, train_recall_epoch=0.989, train_f1_epoch=0.990, epoch_avg_train_loss=0.0951]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1071: 'val_loss' reached 0.29980 (best 0.29980), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=8-val_loss=0.30.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 119/119 [01:49<00:00,  1.08it/s, v_num=2, train_loss_step=0.0202, train_acc_step=1.000, train_precision_step=1.000, train_recall_step=1.000, train_f1_step=1.000, val_inference_time=0.0707, val_loss=0.300, val_acc=0.896, val_precision=0.922, val_recall=0.898, val_f1=0.899, epoch_avg_val_loss=0.302, train_loss_epoch=0.0718, train_acc_epoch=0.989, train_precision_epoch=0.993, train_recall_epoch=0.989, train_f1_epoch=0.990, epoch_avg_train_loss=0.0951]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
    "\n",
    "callbacks = [\n",
    "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
    "        mode=\"max\",  # Maximiert die Genauigkeit\n",
    "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
    "    )\n",
    "]\n",
    "model = ResNet50Classifier(num_classes=9)\n",
    "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"resnet50\", callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
