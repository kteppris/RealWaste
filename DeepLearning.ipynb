{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": [],
        "id": "kDmxGlG8ql5x"
      },
      "outputs": [],
      "source": [
        "# später anpassen für colab und lokal\n",
        "\n",
        "data_path = \"./data\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n"
      ],
      "metadata": {
        "id": "QCzgib0nrNc7",
        "outputId": "67e67749-7084-46cf-fc22-e930898fbc0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.0.post0-py3-none-any.whl (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.9/800.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.9.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.10.1 pytorch-lightning-2.2.0.post0 torchmetrics-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "id": "SgU_-s9Kql52"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import LightningDataModule\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "class ConfigurableDataModule(LightningDataModule):\n",
        "    \"\"\"Class wraper für mit austauschbaren transforms\"\"\"\n",
        "    def __init__(self, data_dir: str, batch_size: int, transform):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Erstellen des Datensatzes als Instanz von ImageFolder\n",
        "        full_dataset = ImageFolder(root=self.data_dir, transform=self.transform)\n",
        "        # Setzen der Trainingsset/Validierungsset Größe\n",
        "        train_size = int(0.8 * len(full_dataset))\n",
        "        val_size = len(full_dataset) - train_size\n",
        "        # Zufälliges aufteilen in Training- und Validierungdatensatz\n",
        "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Setzen des Traindataloader\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # Setzen des Validation Dataloader\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=os.cpu_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "id": "U8RCGtTdql54"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torchmetrics\n",
        "from torchmetrics import MeanMetric\n",
        "import torchvision\n",
        "import torchvision.transforms.functional as F\n",
        "import torchvision.utils as vutils\n",
        "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
        "import random\n",
        "import time\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "class BaseWasteClassifier(pl.LightningModule):\n",
        "    CLASS_NAMES = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
        "\n",
        "    def __init__(self, num_classes: int, results_dir=\"results\"):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        # Get the class name of the model instance\n",
        "        model_class_name = self.__class__.__name__\n",
        "        # Initialize paths\n",
        "        self.results_dir = Path(results_dir) / model_class_name\n",
        "        self.models_dir = self.results_dir / \"models\"\n",
        "        self.images_dir = self.results_dir / \"images\"\n",
        "        self.plots_dir = self.results_dir / \"plots\"\n",
        "\n",
        "        # Create directories if they don't exist\n",
        "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.models_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.images_dir.mkdir(parents=True, exist_ok=True)\n",
        "        self.plots_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Placeholder for the actual model\n",
        "        self.model = None\n",
        "\n",
        "        # Initialize metrics\n",
        "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='macro')\n",
        "        self.precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average='weighted')\n",
        "        self.recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average='weighted')\n",
        "        self.f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n",
        "\n",
        "        # Initialize metrics for average loss\n",
        "        self.train_loss_metric = torchmetrics.MeanMetric()\n",
        "        self.val_loss_metric = torchmetrics.MeanMetric()\n",
        "        # Initialize metrics for averaging\n",
        "        self.avg_train_losses = []\n",
        "        self.avg_val_losses = []\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
        "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
        "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
        "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
        "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
        "\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        # Log precision, recall, and F1 Score\n",
        "        self.log('train_precision', precision, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('train_recall', recall, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.train_loss_metric(loss)\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        avg_train_loss = self.train_loss_metric.compute()\n",
        "        self.log('epoch_avg_train_loss', avg_train_loss, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.avg_train_losses.append(avg_train_loss.item())\n",
        "        self.train_loss_metric.reset()\n",
        "\n",
        "    def on_validation_start(self):\n",
        "        self.clear_images_directory()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        start_time = time.perf_counter()  # Start timing for inference speed\n",
        "\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
        "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
        "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
        "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
        "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
        "\n",
        "        inference_time = time.perf_counter() - start_time  # Stop timing for inference speed\n",
        "        self.log('val_inference_time', inference_time, prog_bar=True, logger=True)\n",
        "\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "        # Log precision, recall, and F1 Score\n",
        "        self.log('val_precision', precision, prog_bar=True)\n",
        "        self.log('val_recall', recall, prog_bar=True)\n",
        "        self.log('val_f1', f1, prog_bar=True)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)  # Convert logits to predicted class indices\n",
        "\n",
        "        if random.random() < 0.1:  # Log images randomly\n",
        "            self.log_images_with_labels(x, y, predictions, batch_idx)\n",
        "\n",
        "        self.val_loss_metric(loss)\n",
        "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # Compute the average losses for the current epoch\n",
        "        avg_val_loss = self.val_loss_metric.compute()\n",
        "\n",
        "        # Log the average losses\n",
        "        self.log('epoch_avg_val_loss', avg_val_loss, on_epoch=True, prog_bar=True, logger=True)\n",
        "\n",
        "        # Append the average losses to the lists for plotting\n",
        "        self.avg_val_losses.append(avg_val_loss.item())\n",
        "\n",
        "        # Reset the metrics for the next epoch\n",
        "        self.val_loss_metric.reset()\n",
        "\n",
        "        # Plot and save the loss curves\n",
        "        self.plot_and_save_loss_curves()\n",
        "\n",
        "\n",
        "    def log_images_with_labels(self, images, labels, predictions, batch_idx):\n",
        "        \"\"\"Save a batch of images with their actual and predicted labels, organized by class name and model class.\"\"\"\n",
        "        annotated_images = []\n",
        "        for i, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
        "            # Unnormalize the image for visualization\n",
        "            image = self.unnormalize(image)  # Make sure to call with self if it's an instance method\n",
        "            # Determine class name for the actual label\n",
        "            actual_class_name = self.CLASS_NAMES[label.item()]\n",
        "\n",
        "            # Ensure the class-specific directory exists within the model class directory\n",
        "            image_dir = self.images_dir / actual_class_name\n",
        "            image_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Convert to PIL Image for easy manipulation\n",
        "            pil_img = F.to_pil_image(image)\n",
        "\n",
        "            # Annotate image with actual and predicted labels\n",
        "            draw = ImageDraw.Draw(pil_img)\n",
        "            annotation_text = f'Actual: {actual_class_name}, Predicted: {self.CLASS_NAMES[prediction.item()]}'\n",
        "            draw.text((10, 10), annotation_text, fill=\"white\")\n",
        "\n",
        "            # Define the file path for saving the image within the specific class directory\n",
        "            file_path = image_dir / f\"epoch_{self.current_epoch}_batch_{batch_idx}_image_{i}.png\"\n",
        "\n",
        "            # Save the annotated image\n",
        "            pil_img.save(file_path)\n",
        "\n",
        "            # Convert back to tensor and add to list\n",
        "            annotated_img = to_tensor(pil_img)\n",
        "            annotated_images.append(annotated_img.unsqueeze(0))  # Add batch dimension\n",
        "\n",
        "        # Stack all annotated images into a single tensor for logging\n",
        "        annotated_images_tensor = torch.cat(annotated_images, dim=0)\n",
        "        img_grid = torchvision.utils.make_grid(annotated_images_tensor, nrow=4)\n",
        "\n",
        "        # Log the grid of annotated images\n",
        "        self.logger.experiment.add_image(f'Validation Images, Batch {batch_idx}', img_grid, self.current_epoch)\n",
        "\n",
        "    def clear_images_directory(self):\n",
        "        if self.images_dir.exists() and self.images_dir.is_dir():\n",
        "            for class_dir in self.images_dir.iterdir():\n",
        "                if class_dir.is_dir():  # Ensure it's a directory\n",
        "                    shutil.rmtree(class_dir)  # Delete the directory and all its contents\n",
        "\n",
        "    def plot_and_save_loss_curves(self):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(range(len(self.avg_train_losses)), self.avg_train_losses, label='Average Training Loss')\n",
        "        plt.plot(range(len(self.avg_val_losses)), self.avg_val_losses, label='Average Validation Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Average Training and Validation Loss Over Epochs')\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "\n",
        "        plot_path = self.plots_dir / \"average_loss_curves.png\"\n",
        "        plt.savefig(plot_path)\n",
        "        plt.close()\n",
        "\n",
        "    def unnormalize(self, image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "        \"\"\"Revert normalization of an image tensor.\"\"\"\n",
        "        image = image.clone()  # Clone the tensor to avoid in-place operations\n",
        "        for t, m, s in zip(image, mean, std):\n",
        "            t.mul_(s).add_(m)  # Multiply by std and add mean\n",
        "        return image\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Subclasses can override this if needed\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "tags": [],
        "id": "7kmzZDxIql56"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "\n",
        "def train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"model_logs\", callbacks=[]):\n",
        "    # Configure the ModelCheckpoint callback\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        dirpath=model.models_dir,\n",
        "        filename='{epoch}-{val_loss:.2f}',\n",
        "        save_top_k=2,  # Save only the best checkpoint\n",
        "        verbose=True,\n",
        "        monitor='val_loss',  # Monitor validation loss (change to val_acc or any other metric as needed)\n",
        "        mode='min',  # 'min' for loss (use 'max' for accuracy)\n",
        "    )\n",
        "    callbacks.append(checkpoint_callback)\n",
        "    # Starten das Trainingsprozesses\n",
        "    logger = TensorBoardLogger(log_dir, name=logger_name)\n",
        "    trainer = Trainer(max_epochs=max_epochs, logger=logger, callbacks=callbacks)\n",
        "    trainer.fit(model, datamodule=data_module)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKqV1kPwql57"
      },
      "source": [
        "## SimpleCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "stK7oXZaql59"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes=9, lr=1e-3):\n",
        "        self.lr = 1e-3\n",
        "        super().__init__(num_classes)\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 28 * 28, 512),  # Bestätigt, dass dies für eine Eingabegröße von 224x224 korrekt ist\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5), # Overfitting vermeiden\n",
        "            nn.Linear(512, num_classes) # lineare Schicht auf die Klassen\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "        return optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW-lELRVql5-"
      },
      "source": [
        "### Train SimpleCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "hn4sl11Fql5_"
      },
      "outputs": [],
      "source": [
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir=tb_logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "tPOe3tRGql5_"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "# Definiere die Transformationspipeline\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Skaliere alle Bilder auf 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ZEl4KjKvql6A"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
        "\n",
        "callbacks = [\n",
        "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
        "        mode=\"max\",  # Maximiert die Genauigkeit\n",
        "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
        "    )\n",
        "]\n",
        "model = SimpleCNN(num_classes=9, lr=1e-3)\n",
        "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"simple_CNN\", callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qt1XlBFql6B"
      },
      "source": [
        "## InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGX2zWN7ql6B"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import inception_v3\n",
        "\n",
        "class InceptionWasteClassifier(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__(num_classes)\n",
        "        self.model = inception_v3(weights=\"Inception_V3_Weights.DEFAULT\")\n",
        "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            outputs = self.model(x)\n",
        "            return outputs.logits, outputs.aux_logits\n",
        "        else:\n",
        "            return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        outputs = self(x)  # This could be either a tensor or a tuple of tensors\n",
        "        logits = outputs if isinstance(outputs, torch.Tensor) else outputs[0]  # Select logits\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
        "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPKSXorZql6C"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import InterpolationMode\n",
        "# Define the transformations as per Inception V3's requirements\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(342, interpolation=InterpolationMode.BILINEAR),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI4WNJ5lql6D",
        "outputId": "a131f21f-9b73-4d37-ba8c-79a091fa9430"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\Felix\\Desktop\\RealWaste\\results\\InceptionWasteClassifier\\models exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name              | Type                | Params\n",
            "----------------------------------------------------------\n",
            "0 | accuracy          | MulticlassAccuracy  | 0     \n",
            "1 | precision         | MulticlassPrecision | 0     \n",
            "2 | recall            | MulticlassRecall    | 0     \n",
            "3 | f1_score          | MulticlassF1Score   | 0     \n",
            "4 | train_loss_metric | MeanMetric          | 0     \n",
            "5 | val_loss_metric   | MeanMetric          | 0     \n",
            "6 | model             | Inception3          | 25.1 M\n",
            "----------------------------------------------------------\n",
            "25.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "25.1 M    Total params\n",
            "100.523   Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 119/119 [01:25<00:00,  1.40it/s, v_num=1, train_loss_step=1.030, train_acc_step=0.507, val_inference_time=0.100, val_loss=0.849, val_acc=0.744, val_precision=0.803, val_recall=0.776, val_f1=0.768, epoch_avg_val_loss=0.849, train_loss_epoch=1.570, train_acc_epoch=0.441]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: The ``compute`` method of metric MeanMetric was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n",
            "Epoch 0, global step 119: 'val_loss' reached 0.84873 (best 0.84873), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\InceptionWasteClassifier\\\\models\\\\epoch=0-val_loss=0.85.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:   0%|          | 0/119 [00:00<?, ?it/s, v_num=1, train_loss_step=1.030, train_acc_step=0.507, val_inference_time=0.100, val_loss=0.849, val_acc=0.744, val_precision=0.803, val_recall=0.776, val_f1=0.768, epoch_avg_val_loss=0.849, train_loss_epoch=1.570, train_acc_epoch=0.441]          "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000001E6D05779C0>\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1437, in _shutdown_workers\n",
            "    if self._persistent_workers or self._workers_status[worker_id]:\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n"
          ]
        }
      ],
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
        "\n",
        "callbacks = [\n",
        "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
        "        mode=\"max\",  # Maximiert die Genauigkeit\n",
        "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
        "    )\n",
        "]\n",
        "model = InceptionWasteClassifier(num_classes=9)\n",
        "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"inceptionv3\", callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioVcGkSEql6F"
      },
      "source": [
        "## DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3WLD-Aiql6F"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import densenet201\n",
        "\n",
        "class DenseNet201Classifier(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__(num_classes)\n",
        "        self.model = densenet201(weights=\"DenseNet201_Weights.DEFAULT\")\n",
        "        self.model.classifier = torch.nn.Linear(self.model.classifier.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQAxV9OQql6G"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import InterpolationMode\n",
        "# Define the transformations as per Inception V3's requirements\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pUas5GSql6H",
        "outputId": "43d4ebd7-3600-40ca-a697-750cb8ee88ff"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\Felix\\Desktop\\RealWaste\\results\\DenseNet201Classifier\\models exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name              | Type                | Params\n",
            "----------------------------------------------------------\n",
            "0 | accuracy          | MulticlassAccuracy  | 0     \n",
            "1 | precision         | MulticlassPrecision | 0     \n",
            "2 | recall            | MulticlassRecall    | 0     \n",
            "3 | f1_score          | MulticlassF1Score   | 0     \n",
            "4 | train_loss_metric | MeanMetric          | 0     \n",
            "5 | val_loss_metric   | MeanMetric          | 0     \n",
            "6 | model             | DenseNet            | 18.1 M\n",
            "----------------------------------------------------------\n",
            "18.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "18.1 M    Total params\n",
            "72.441    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0:   3%|▎         | 3/119 [00:31<20:27,  0.09it/s, v_num=6, train_loss_step=2.260, train_acc_step=0.180, train_precision_step=0.215, train_recall_step=0.125, train_f1_step=0.122]  "
          ]
        }
      ],
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
        "\n",
        "callbacks = [\n",
        "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
        "        mode=\"max\",  # Maximiert die Genauigkeit\n",
        "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
        "    )\n",
        "]\n",
        "model = DenseNet201Classifier(num_classes=9)\n",
        "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"densenet201\", callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBJVZ1M1ql6H"
      },
      "source": [
        "## Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aySV_quql6I"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50\n",
        "\n",
        "class ResNet50Classifier(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__(num_classes)\n",
        "        self.model = resnet50(weights=\"ResNet50_Weights.DEFAULT\")\n",
        "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moa7GEm8ql6J"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhMoMa5gql6J",
        "outputId": "526f8ff4-8f6a-4a14-889d-c57640494284"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\Felix/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:03<00:00, 33.4MB/s]\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\Felix\\Desktop\\RealWaste\\results\\ResNet50Classifier\\models exists and is not empty.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name              | Type                | Params\n",
            "----------------------------------------------------------\n",
            "0 | accuracy          | MulticlassAccuracy  | 0     \n",
            "1 | precision         | MulticlassPrecision | 0     \n",
            "2 | recall            | MulticlassRecall    | 0     \n",
            "3 | f1_score          | MulticlassF1Score   | 0     \n",
            "4 | train_loss_metric | MeanMetric          | 0     \n",
            "5 | val_loss_metric   | MeanMetric          | 0     \n",
            "6 | model             | ResNet              | 23.5 M\n",
            "----------------------------------------------------------\n",
            "23.5 M    Trainable params\n",
            "0         Non-trainable params\n",
            "23.5 M    Total params\n",
            "94.106    Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'val_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           \r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Felix\\anaconda3\\envs\\cudatest\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: 100%|██████████| 119/119 [01:14<00:00,  1.59it/s, v_num=2, train_loss_step=1.320, train_acc_step=0.497, train_precision_step=0.723, train_recall_step=0.600, train_f1_step=0.640, val_inference_time=0.0874, val_loss=1.190, val_acc=0.672, val_precision=0.729, val_recall=0.697, val_f1=0.672, epoch_avg_val_loss=1.190, train_loss_epoch=1.730, train_acc_epoch=0.390, train_precision_epoch=0.451, train_recall_epoch=0.445, train_f1_epoch=0.396]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0, global step 119: 'val_loss' reached 1.18902 (best 1.18902), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=0-val_loss=1.19.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|██████████| 119/119 [01:48<00:00,  1.10it/s, v_num=2, train_loss_step=0.820, train_acc_step=0.704, train_precision_step=0.780, train_recall_step=0.680, train_f1_step=0.694, val_inference_time=0.0785, val_loss=0.669, val_acc=0.789, val_precision=0.839, val_recall=0.793, val_f1=0.790, epoch_avg_val_loss=0.672, train_loss_epoch=0.882, train_acc_epoch=0.738, train_precision_epoch=0.799, train_recall_epoch=0.749, train_f1_epoch=0.745, epoch_avg_train_loss=1.730]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1, global step 238: 'val_loss' reached 0.66946 (best 0.66946), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=1-val_loss=0.67.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|██████████| 119/119 [01:51<00:00,  1.06it/s, v_num=2, train_loss_step=0.527, train_acc_step=0.875, train_precision_step=0.903, train_recall_step=0.840, train_f1_step=0.855, val_inference_time=0.0819, val_loss=0.487, val_acc=0.830, val_precision=0.875, val_recall=0.838, val_f1=0.839, epoch_avg_val_loss=0.490, train_loss_epoch=0.526, train_acc_epoch=0.843, train_precision_epoch=0.881, train_recall_epoch=0.845, train_f1_epoch=0.847, epoch_avg_train_loss=0.881]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2, global step 357: 'val_loss' reached 0.48689 (best 0.48689), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=2-val_loss=0.49.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|██████████| 119/119 [01:41<00:00,  1.18it/s, v_num=2, train_loss_step=0.304, train_acc_step=0.824, train_precision_step=0.938, train_recall_step=0.880, train_f1_step=0.894, val_inference_time=0.0746, val_loss=0.409, val_acc=0.860, val_precision=0.897, val_recall=0.863, val_f1=0.865, epoch_avg_val_loss=0.412, train_loss_epoch=0.353, train_acc_epoch=0.886, train_precision_epoch=0.921, train_recall_epoch=0.894, train_f1_epoch=0.896, epoch_avg_train_loss=0.526]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3, global step 476: 'val_loss' reached 0.40861 (best 0.40861), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=3-val_loss=0.41.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 119/119 [01:49<00:00,  1.08it/s, v_num=2, train_loss_step=0.143, train_acc_step=0.975, train_precision_step=0.973, train_recall_step=0.960, train_f1_step=0.962, val_inference_time=0.0917, val_loss=0.369, val_acc=0.880, val_precision=0.914, val_recall=0.882, val_f1=0.883, epoch_avg_val_loss=0.372, train_loss_epoch=0.257, train_acc_epoch=0.926, train_precision_epoch=0.944, train_recall_epoch=0.926, train_f1_epoch=0.927, epoch_avg_train_loss=0.353]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4, global step 595: 'val_loss' reached 0.36919 (best 0.36919), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=4-val_loss=0.37.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|██████████| 119/119 [01:45<00:00,  1.13it/s, v_num=2, train_loss_step=0.216, train_acc_step=0.963, train_precision_step=0.960, train_recall_step=0.920, train_f1_step=0.925, val_inference_time=0.0723, val_loss=0.330, val_acc=0.888, val_precision=0.915, val_recall=0.891, val_f1=0.892, epoch_avg_val_loss=0.332, train_loss_epoch=0.182, train_acc_epoch=0.951, train_precision_epoch=0.968, train_recall_epoch=0.953, train_f1_epoch=0.955, epoch_avg_train_loss=0.257] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5, global step 714: 'val_loss' reached 0.33008 (best 0.33008), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=5-val_loss=0.33.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|██████████| 119/119 [01:41<00:00,  1.17it/s, v_num=2, train_loss_step=0.253, train_acc_step=0.805, train_precision_step=0.948, train_recall_step=0.880, train_f1_step=0.903, val_inference_time=0.0601, val_loss=0.326, val_acc=0.892, val_precision=0.921, val_recall=0.893, val_f1=0.895, epoch_avg_val_loss=0.327, train_loss_epoch=0.134, train_acc_epoch=0.964, train_precision_epoch=0.980, train_recall_epoch=0.968, train_f1_epoch=0.970, epoch_avg_train_loss=0.182] "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6, global step 833: 'val_loss' reached 0.32555 (best 0.32555), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=6-val_loss=0.33.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|██████████| 119/119 [01:49<00:00,  1.09it/s, v_num=2, train_loss_step=0.0475, train_acc_step=1.000, train_precision_step=1.000, train_recall_step=1.000, train_f1_step=1.000, val_inference_time=0.0691, val_loss=0.311, val_acc=0.898, val_precision=0.918, val_recall=0.898, val_f1=0.898, epoch_avg_val_loss=0.313, train_loss_epoch=0.0952, train_acc_epoch=0.981, train_precision_epoch=0.988, train_recall_epoch=0.983, train_f1_epoch=0.983, epoch_avg_train_loss=0.134]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7, global step 952: 'val_loss' reached 0.31137 (best 0.31137), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=7-val_loss=0.31.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 119/119 [01:49<00:00,  1.09it/s, v_num=2, train_loss_step=0.0202, train_acc_step=1.000, train_precision_step=1.000, train_recall_step=1.000, train_f1_step=1.000, val_inference_time=0.0707, val_loss=0.300, val_acc=0.896, val_precision=0.922, val_recall=0.898, val_f1=0.899, epoch_avg_val_loss=0.302, train_loss_epoch=0.0718, train_acc_epoch=0.989, train_precision_epoch=0.993, train_recall_epoch=0.989, train_f1_epoch=0.990, epoch_avg_train_loss=0.0951]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8, global step 1071: 'val_loss' reached 0.29980 (best 0.29980), saving model to 'C:\\\\Users\\\\Felix\\\\Desktop\\\\RealWaste\\\\results\\\\ResNet50Classifier\\\\models\\\\epoch=8-val_loss=0.30.ckpt' as top 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|██████████| 119/119 [01:49<00:00,  1.08it/s, v_num=2, train_loss_step=0.0202, train_acc_step=1.000, train_precision_step=1.000, train_recall_step=1.000, train_f1_step=1.000, val_inference_time=0.0707, val_loss=0.300, val_acc=0.896, val_precision=0.922, val_recall=0.898, val_f1=0.899, epoch_avg_val_loss=0.302, train_loss_epoch=0.0718, train_acc_epoch=0.989, train_precision_epoch=0.993, train_recall_epoch=0.989, train_f1_epoch=0.990, epoch_avg_train_loss=0.0951]\n"
          ]
        }
      ],
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
        "\n",
        "callbacks = [\n",
        "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
        "        mode=\"max\",  # Maximiert die Genauigkeit\n",
        "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
        "    )\n",
        "]\n",
        "model = ResNet50Classifier(num_classes=9)\n",
        "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"resnet50\", callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16"
      ],
      "metadata": {
        "id": "EFTm4lG3rflV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import vgg16\n",
        "\n",
        "class vgg16Classifier(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__(num_classes)\n",
        "        self.model = vgg16(weights=\"VGG16_Weights.DEFAULT\")\n",
        "        self.model.classifier[6] = torch.nn.Linear(self.model.classifier[6].in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "RLudd9a6rnD_"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "wAxxaPCXsQmA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
        "\n",
        "callbacks = [\n",
        "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
        "        mode=\"max\",  # Maximiert die Genauigkeit\n",
        "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
        "    )\n",
        "]\n",
        "model = vgg16Classifier(num_classes=9)\n",
        "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"vgg16\", callbacks=callbacks)"
      ],
      "metadata": {
        "id": "6-qHaqVQshaJ",
        "outputId": "76ab45be-ab44-4f03-9066-c1057c69a7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "WARNING:pytorch_lightning.loggers.tensorboard:Missing logger folder: tb_logs/vgg16\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-1cb13bc9f4f1>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m ]\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tb_logs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vgg16\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-3aa07632cde6>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, data_module, log_dir, max_epochs, logger_name, callbacks)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoardLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         )\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_setup_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# allow user to set up LightningModule in accelerator environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.__class__.__name__}: configuring model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_configure_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_setup_hook\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0m_call_lightning_datamodule_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"setup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"setup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0m_call_lightning_module_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"setup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_lightning_datamodule_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[LightningDataModule]{trainer.datamodule.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-2d6cf974c408>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Erstellen des Datensatzes als Instanz von ImageFolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mfull_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Setzen der Trainingsset/Validierungsset Größe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ) -> None:\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \"\"\"\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \"\"\"\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}