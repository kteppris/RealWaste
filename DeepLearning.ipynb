{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# später anpassen für colab und lokal\n",
    "\n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "class ConfigurableDataModule(LightningDataModule):\n",
    "    \"\"\"Class wraper für mit austauschbaren transforms\"\"\"\n",
    "    def __init__(self, data_dir: str, batch_size: int, transform):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Erstellen des Datensatzes als Instanz von ImageFolder\n",
    "        full_dataset = ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        # Setzen der Trainingsset/Validierungsset Größe\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        # Zufälliges aufteilen in Training- und Validierungdatensatz\n",
    "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Setzen des Traindataloader\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Setzen des Validation Dataloader\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanMetric\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "class BaseWasteClassifier(pl.LightningModule):\n",
    "    CLASS_NAMES = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
    "\n",
    "    def __init__(self, num_classes: int, results_dir=\"results\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # Get the class name of the model instance\n",
    "        model_class_name = self.__class__.__name__\n",
    "        # Initialize paths\n",
    "        self.results_dir = Path(results_dir) / model_class_name\n",
    "        self.models_dir = self.results_dir / \"models\"\n",
    "        self.images_dir = self.results_dir / \"images\"\n",
    "        self.plots_dir = self.results_dir / \"plots\"\n",
    "\n",
    "        # Create directories if they don't exist\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.models_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.plots_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Placeholder for the actual model\n",
    "        self.model = None\n",
    "\n",
    "        # Initialize metrics\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='macro')\n",
    "        self.precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "        self.recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "        self.f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "\n",
    "        # Initialize metrics for average loss\n",
    "        self.train_loss_metric = torchmetrics.MeanMetric()\n",
    "        self.val_loss_metric = torchmetrics.MeanMetric()\n",
    "        # Initialize metrics for averaging\n",
    "        self.avg_train_losses = []\n",
    "        self.avg_val_losses = []\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
    "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
    "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
    "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        # Log precision, recall, and F1 Score\n",
    "        self.log('train_precision', precision, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_recall', recall, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.train_loss_metric(loss)\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        avg_train_loss = self.train_loss_metric.compute()\n",
    "        self.log('epoch_avg_train_loss', avg_train_loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.avg_train_losses.append(avg_train_loss.item())\n",
    "        self.train_loss_metric.reset()\n",
    "\n",
    "    def on_validation_start(self):\n",
    "        self.clear_images_directory()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        start_time = time.perf_counter()  # Start timing for inference speed\n",
    "        \n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
    "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
    "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
    "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
    "        \n",
    "        inference_time = time.perf_counter() - start_time  # Stop timing for inference speed\n",
    "        self.log('val_inference_time', inference_time, prog_bar=True, logger=True)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        # Log precision, recall, and F1 Score\n",
    "        self.log('val_precision', precision, prog_bar=True)\n",
    "        self.log('val_recall', recall, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)  # Convert logits to predicted class indices\n",
    "\n",
    "        if random.random() < 0.1:  # Log images randomly\n",
    "            self.log_images_with_labels(x, y, predictions, batch_idx)\n",
    "        \n",
    "        self.val_loss_metric(loss)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Compute the average losses for the current epoch\n",
    "        avg_val_loss = self.val_loss_metric.compute()\n",
    "\n",
    "        # Log the average losses\n",
    "        self.log('epoch_avg_val_loss', avg_val_loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # Append the average losses to the lists for plotting\n",
    "        self.avg_val_losses.append(avg_val_loss.item())\n",
    "\n",
    "        # Reset the metrics for the next epoch\n",
    "        self.val_loss_metric.reset()\n",
    "\n",
    "        # Plot and save the loss curves\n",
    "        self.plot_and_save_loss_curves()\n",
    "\n",
    "\n",
    "    def log_images_with_labels(self, images, labels, predictions, batch_idx):\n",
    "        \"\"\"Save a batch of images with their actual and predicted labels, organized by class name and model class.\"\"\"\n",
    "        annotated_images = []\n",
    "        for i, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "            # Unnormalize the image for visualization\n",
    "            image = self.unnormalize(image)  # Make sure to call with self if it's an instance method\n",
    "            # Determine class name for the actual label\n",
    "            actual_class_name = self.CLASS_NAMES[label.item()]\n",
    "\n",
    "            # Ensure the class-specific directory exists within the model class directory\n",
    "            image_dir = self.images_dir / actual_class_name\n",
    "            image_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Convert to PIL Image for easy manipulation\n",
    "            pil_img = F.to_pil_image(image)\n",
    "\n",
    "            # Annotate image with actual and predicted labels\n",
    "            draw = ImageDraw.Draw(pil_img)\n",
    "            annotation_text = f'Actual: {actual_class_name}, Predicted: {self.CLASS_NAMES[prediction.item()]}'\n",
    "            draw.text((10, 10), annotation_text, fill=\"white\")\n",
    "\n",
    "            # Define the file path for saving the image within the specific class directory\n",
    "            file_path = image_dir / f\"epoch_{self.current_epoch}_batch_{batch_idx}_image_{i}.png\"\n",
    "\n",
    "            # Save the annotated image\n",
    "            pil_img.save(file_path)\n",
    "\n",
    "            # Convert back to tensor and add to list\n",
    "            annotated_img = to_tensor(pil_img)\n",
    "            annotated_images.append(annotated_img.unsqueeze(0))  # Add batch dimension\n",
    "\n",
    "        # Stack all annotated images into a single tensor for logging\n",
    "        annotated_images_tensor = torch.cat(annotated_images, dim=0)\n",
    "        img_grid = torchvision.utils.make_grid(annotated_images_tensor, nrow=4)\n",
    "\n",
    "        # Log the grid of annotated images\n",
    "        self.logger.experiment.add_image(f'Validation Images, Batch {batch_idx}', img_grid, self.current_epoch)\n",
    "\n",
    "    def clear_images_directory(self):\n",
    "        if self.images_dir.exists() and self.images_dir.is_dir():\n",
    "            for class_dir in self.images_dir.iterdir():\n",
    "                if class_dir.is_dir():  # Ensure it's a directory\n",
    "                    shutil.rmtree(class_dir)  # Delete the directory and all its contents  \n",
    "    \n",
    "    def plot_and_save_loss_curves(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(len(self.avg_train_losses)), self.avg_train_losses, label='Average Training Loss')\n",
    "        plt.plot(range(len(self.avg_val_losses)), self.avg_val_losses, label='Average Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Average Training and Validation Loss Over Epochs')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plot_path = self.plots_dir / \"average_loss_curves.png\"\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "\n",
    "    def unnormalize(self, image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        \"\"\"Revert normalization of an image tensor.\"\"\"\n",
    "        image = image.clone()  # Clone the tensor to avoid in-place operations\n",
    "        for t, m, s in zip(image, mean, std):\n",
    "            t.mul_(s).add_(m)  # Multiply by std and add mean\n",
    "        return image\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Subclasses can override this if needed\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "def train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"model_logs\", callbacks=[]):\n",
    "    # Configure the ModelCheckpoint callback\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=model.models_dir,\n",
    "        filename='{epoch}-{val_loss:.2f}',\n",
    "        save_top_k=2,  # Save only the best checkpoint\n",
    "        verbose=True,\n",
    "        monitor='val_loss',  # Monitor validation loss (change to val_acc or any other metric as needed)\n",
    "        mode='min',  # 'min' for loss (use 'max' for accuracy)\n",
    "    )\n",
    "    callbacks.append(checkpoint_callback)\n",
    "    # Starten das Trainingsprozesses\n",
    "    logger = TensorBoardLogger(log_dir, name=logger_name)\n",
    "    trainer = Trainer(max_epochs=max_epochs, logger=logger, callbacks=callbacks)\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(BaseWasteClassifier):\n",
    "    def __init__(self, num_classes=9, lr=1e-3):\n",
    "        self.lr = 1e-3\n",
    "        super().__init__(num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 512),  # Bestätigt, dass dies für eine Eingabegröße von 224x224 korrekt ist\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # Overfitting vermeiden\n",
    "            nn.Linear(512, num_classes) # lineare Schicht auf die Klassen\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c1cc83c15c820532\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c1cc83c15c820532\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=tb_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Definiere die Transformationspipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Skaliere alle Bilder auf 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "2024-02-24 01:30:13.029517: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-24 01:30:13.029563: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-24 01:30:13.030208: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-24 01:30:13.033807: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-24 01:30:13.589046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/results/SimpleCNN/models exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                | Params\n",
      "----------------------------------------------------------\n",
      "0 | accuracy          | MulticlassAccuracy  | 0     \n",
      "1 | precision         | MulticlassPrecision | 0     \n",
      "2 | recall            | MulticlassRecall    | 0     \n",
      "3 | f1_score          | MulticlassF1Score   | 0     \n",
      "4 | train_loss_metric | MeanMetric          | 0     \n",
      "5 | val_loss_metric   | MeanMetric          | 0     \n",
      "6 | model             | Sequential          | 25.7 M\n",
      "----------------------------------------------------------\n",
      "25.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "25.7 M    Total params\n",
      "102.875   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e4c038b08f4d159e4f3aea3b616534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 119: 'val_loss' reached 1.33447 (best 1.33447), saving model to '/home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/results/SimpleCNN/models/epoch=0-val_loss=1.33.ckpt' as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 238: 'val_loss' reached 1.12750 (best 1.12750), saving model to '/home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/results/SimpleCNN/models/epoch=1-val_loss=1.13.ckpt' as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 357: 'val_loss' reached 1.04771 (best 1.04771), saving model to '/home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/results/SimpleCNN/models/epoch=2-val_loss=1.05.ckpt' as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 476: 'val_loss' reached 0.95307 (best 0.95307), saving model to '/home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/results/SimpleCNN/models/epoch=3-val_loss=0.95.ckpt' as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 595: 'val_loss' reached 0.90840 (best 0.90840), saving model to '/home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/results/SimpleCNN/models/epoch=4-val_loss=0.91.ckpt' as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 714: 'val_loss' reached 0.93166 (best 0.90840), saving model to '/home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/results/SimpleCNN/models/epoch=5-val_loss=0.93.ckpt' as top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 833: 'val_loss' was not in top 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 952: 'val_loss' was not in top 2\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
    "\n",
    "callbacks = [\n",
    "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
    "        mode=\"max\",  # Maximiert die Genauigkeit\n",
    "        patience=1,  # \"Wartet\" 1 Epoche ohne Verbesserung\n",
    "    )\n",
    "]\n",
    "model = SimpleCNN(num_classes=9, lr=1e-3)\n",
    "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"simple_CNN\", callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
