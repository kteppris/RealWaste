{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# später anpassen für colab und lokal\n",
    "\n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "\n",
    "class ConfigurableDataModule(LightningDataModule):\n",
    "    \"\"\"Class wraper für mit austauschbaren transforms\"\"\"\n",
    "    def __init__(self, data_dir: str, batch_size: int, transform):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Erstellen des Datensatzes als Instanz von ImageFolder\n",
    "        full_dataset = ImageFolder(root=self.data_dir, transform=self.transform)\n",
    "        # Setzen der Trainingsset/Validierungsset Größe\n",
    "        train_size = int(0.8 * len(full_dataset))\n",
    "        val_size = len(full_dataset) - train_size\n",
    "        # Zufälliges aufteilen in Training- und Validierungdatensatz\n",
    "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # Setzen des Traindataloader\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # Setzen des Validation Dataloader\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import MeanMetric\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.transforms.functional import to_pil_image, to_tensor\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "class BaseWasteClassifier(pl.LightningModule):\n",
    "    CLASS_NAMES = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
    "\n",
    "    def __init__(self, num_classes: int, results_dir=\"results\"):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # Get the class name of the model instance\n",
    "        model_class_name = self.__class__.__name__\n",
    "        # Initialize paths\n",
    "        self.results_dir = Path(results_dir) / model_class_name\n",
    "        self.models_dir = self.results_dir / \"models\"\n",
    "        self.images_dir = self.results_dir / \"images\"\n",
    "        self.logs_dir = self.results_dir / \"logs\"\n",
    "\n",
    "        # Create directories if they don't exist\n",
    "        self.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.models_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Placeholder for the actual model\n",
    "        self.model = None\n",
    "\n",
    "        # Initialize metrics\n",
    "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='macro')\n",
    "        self.precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "        self.recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "        self.f1_score = torchmetrics.F1Score(task='multiclass', num_classes=num_classes, average='weighted')\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
    "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
    "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
    "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
    "        \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        # Log precision, recall, and F1 Score\n",
    "        self.log('train_precision', precision, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_recall', recall, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_f1', f1, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_start(self):\n",
    "        self.clear_images_directory()\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        start_time = time.perf_counter()  # Start timing for inference speed\n",
    "        \n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
    "        precision = self.precision(torch.argmax(logits, dim=1), y)\n",
    "        recall = self.recall(torch.argmax(logits, dim=1), y)\n",
    "        f1 = self.f1_score(torch.argmax(logits, dim=1), y)  # Calculate F1 Score\n",
    "        \n",
    "        inference_time = time.perf_counter() - start_time  # Stop timing for inference speed\n",
    "        self.log('val_inference_time', inference_time, prog_bar=True, logger=True)\n",
    "        \n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        # Log precision, recall, and F1 Score\n",
    "        self.log('val_precision', precision, prog_bar=True)\n",
    "        self.log('val_recall', recall, prog_bar=True)\n",
    "        self.log('val_f1', f1, prog_bar=True)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=1)  # Convert logits to predicted class indices\n",
    "\n",
    "        if random.random() < 0.1:  # Log images randomly\n",
    "            self.log_images_with_labels(x, y, predictions, batch_idx)\n",
    "        return loss\n",
    "\n",
    "    def log_images_with_labels(self, images, labels, predictions, batch_idx):\n",
    "        \"\"\"Save a batch of images with their actual and predicted labels, organized by class name and model class.\"\"\"\n",
    "        annotated_images = []\n",
    "        for i, (image, label, prediction) in enumerate(zip(images, labels, predictions)):\n",
    "            # Unnormalize the image for visualization\n",
    "            image = self.unnormalize(image)  # Make sure to call with self if it's an instance method\n",
    "            # Determine class name for the actual label\n",
    "            actual_class_name = self.CLASS_NAMES[label.item()]\n",
    "\n",
    "            # Ensure the class-specific directory exists within the model class directory\n",
    "            image_dir = self.images_dir / actual_class_name\n",
    "            image_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Convert to PIL Image for easy manipulation\n",
    "            pil_img = F.to_pil_image(image)\n",
    "\n",
    "            # Annotate image with actual and predicted labels\n",
    "            draw = ImageDraw.Draw(pil_img)\n",
    "            annotation_text = f'Actual: {actual_class_name}, Predicted: {self.CLASS_NAMES[prediction.item()]}'\n",
    "            draw.text((10, 10), annotation_text, fill=\"white\")\n",
    "\n",
    "            # Define the file path for saving the image within the specific class directory\n",
    "            file_path = image_dir / f\"epoch_{self.current_epoch}_batch_{batch_idx}_image_{i}.png\"\n",
    "\n",
    "            # Save the annotated image\n",
    "            pil_img.save(file_path)\n",
    "\n",
    "            # Convert back to tensor and add to list\n",
    "            annotated_img = to_tensor(pil_img)\n",
    "            annotated_images.append(annotated_img.unsqueeze(0))  # Add batch dimension\n",
    "\n",
    "        # Stack all annotated images into a single tensor for logging\n",
    "        annotated_images_tensor = torch.cat(annotated_images, dim=0)\n",
    "        img_grid = torchvision.utils.make_grid(annotated_images_tensor, nrow=4)\n",
    "\n",
    "        # Log the grid of annotated images\n",
    "        self.logger.experiment.add_image(f'Validation Images, Batch {batch_idx}', img_grid, self.current_epoch)\n",
    "\n",
    "    def clear_images_directory(self):\n",
    "        if self.images_dir.exists() and self.images_dir.is_dir():\n",
    "            for class_dir in self.images_dir.iterdir():\n",
    "                if class_dir.is_dir():  # Ensure it's a directory\n",
    "                    shutil.rmtree(class_dir)  # Delete the directory and all its contents  \n",
    "\n",
    "    def unnormalize(self, image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
    "        \"\"\"Revert normalization of an image tensor.\"\"\"\n",
    "        image = image.clone()  # Clone the tensor to avoid in-place operations\n",
    "        for t, m, s in zip(image, mean, std):\n",
    "            t.mul_(s).add_(m)  # Multiply by std and add mean\n",
    "        return image\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Subclasses can override this if needed\n",
    "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "\n",
    "def get_callbacks(model_checkpoint_path: str, early_stop_patience=2):\n",
    "    callbacks = []\n",
    "    \n",
    "    # Configure the ModelCheckpoint callback\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=model_checkpoint_path,\n",
    "        filename='{epoch}-{val_loss:.2f}',\n",
    "        save_top_k=2,  # Save only the best checkpoint\n",
    "        verbose=True,\n",
    "        monitor='val_loss',  # Monitor validation loss (change to val_acc or any other metric as needed)\n",
    "        mode='min',  # 'min' for loss (use 'max' for accuracy)\n",
    "    )\n",
    "    callbacks.append(checkpoint_callback)\n",
    "    \n",
    "    # Stoppt des Training wenn sich val Metrik nicht verbessert\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor=\"val_acc\",  # Die Metrik beobachtet wird\n",
    "        mode=\"max\",  # Maximiert die Genauigkeit\n",
    "        patience=early_stop_patience,  # \"Wartet\" 2 Epoche ohne Verbesserung\n",
    "    )\n",
    "    callbacks.append(early_stopping_callback)\n",
    "    return callbacks\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "\n",
    "def train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"model_logs\", callbacks=[]):\n",
    "    \n",
    "    # Definieren der logger\n",
    "    tb_logger = TensorBoardLogger(log_dir, name=logger_name)\n",
    "    csv_logger = CSVLogger(model.results_dir, name=\"logs\")\n",
    "    trainer = Trainer(max_epochs=max_epochs, logger=[tb_logger, csv_logger], callbacks=callbacks)\n",
    "    trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleCNN(BaseWasteClassifier):\n",
    "    def __init__(self, num_classes=9, lr=1e-3):\n",
    "        self.lr = 1e-3\n",
    "        super().__init__(num_classes)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 512),  # Bestätigt, dass dies für eine Eingabegröße von 224x224 korrekt ist\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5), # Overfitting vermeiden\n",
    "            nn.Linear(512, num_classes) # lineare Schicht auf die Klassen\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train SimpleCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f6b4287fa3020c3a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f6b4287fa3020c3a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=tb_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "# Definiere die Transformationspipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Skaliere alle Bilder auf 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "data_module = ConfigurableDataModule(data_dir=data_path, batch_size=32, transform=transform)\n",
    "model = SimpleCNN(num_classes=9, lr=1e-3)\n",
    "callbacks = get_callbacks(\n",
    "    model_checkpoint_path=model.models_dir, \n",
    "    early_stop_patience=2\n",
    ")\n",
    "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"simple_CNN\", callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import inception_v3\n",
    "\n",
    "class InceptionWasteClassifier(BaseWasteClassifier):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super().__init__(num_classes)\n",
    "        self.model = inception_v3(aux_logits=True, weights=\"Inception_V3_Weights.DEFAULT\")\n",
    "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            outputs = self.model(x)\n",
    "            return outputs.logits, outputs.aux_logits\n",
    "        else:\n",
    "            return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# Define the transformations as per Inception V3's requirements\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(342, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.CenterCrop(299),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "data_module = ConfigurableDataModule(data_path, batch_size, transform)\n",
    "\n",
    "model = InceptionWasteClassifier()\n",
    "batch_size = 32\n",
    "callbacks = get_callbacks(\n",
    "    model_checkpoint_path=model.models_dir, \n",
    "    early_stop_patience=2\n",
    ")\n",
    "train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=50, logger_name=\"InceptionWaste\", callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
