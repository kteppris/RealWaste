{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "07cedc28-8792-459b-8469-2744ca850a71",
      "metadata": {
        "id": "07cedc28-8792-459b-8469-2744ca850a71"
      },
      "source": [
        "# Training mit Pytorch Lighting\n",
        "\n",
        "Das Paket PyTorch lighting dient als zusätzliche Abstraktionsschicht und erspart große Menge an Code, in welchem sonst die Trainingsloops und Logging etc. programmiert werden müsstens. Mit PyTorch lighting können relativ einfach die vorhanden Klassen anpassen und haben einen kompletten Trainingslauf mit Metrikenanzeige und Logging. Diese Funktionen und Klassen können wir dann einzelnd an die einzelnen Modelle anpassen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f776cc41-922f-4454-949d-7de07bd30c34",
      "metadata": {
        "tags": [],
        "id": "f776cc41-922f-4454-949d-7de07bd30c34"
      },
      "source": [
        "## Download der Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c43148-4ed6-42bf-93c4-0c58096afc27",
      "metadata": {
        "tags": [],
        "id": "08c43148-4ed6-42bf-93c4-0c58096afc27",
        "outputId": "1f256d33-554f-408b-86fd-d2e86a0269e3"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Welcher Pfad soll für den Datensatz benutzt werden? ~/work/Sonstiges/Module/Machine_Learning/RealWaste/data\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path '/home/jovyan/work/Sonstiges/Module/Machine_Learning/RealWaste/data' already exists and is not an empty directory.\n",
            "Dataset Path:  ~/work/Sonstiges/Module/Machine_Learning/RealWaste/data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# Function to check if running in Google Colab\n",
        "def in_colab():\n",
        "    return 'google.colab' in sys.modules\n",
        "\n",
        "# Define the base path for the dataset\n",
        "if in_colab():\n",
        "    !git clone https://github.com/kteppris/RealWaste.git\n",
        "    %cd RealWaste\n",
        "    !pip install -r requirements.txt\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Assuming the dataset is in \"drive/My Drive/RealWaste\" in Google Drive\n",
        "    dataset_path = '/content/drive/MyDrive/RealWasteData'\n",
        "else:\n",
        "    # Path in your local container\n",
        "    dataset_path = input(\"Welcher Pfad soll für den Datensatz benutzt werden?\")\n",
        "\n",
        "# Ensure the dataset directory exists (specifically for local container, as Colab will have it in Drive)\n",
        "if not in_colab():\n",
        "    os.makedirs(dataset_path, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Clone the repository only if the dataset does not already exist\n",
        "if not os.listdir(dataset_path):  # Checks if the dataset directory is empty\n",
        "    !git clone https://github.com/sam-single/realwaste.git {dataset_path}\n",
        "    # Remove unnecessary files and directories\n",
        "    readme_path = os.path.join(dataset_path, 'README.md')\n",
        "    if os.path.exists(readme_path):\n",
        "        os.remove(readme_path)\n",
        "    realwaste_dir = os.path.join(dataset_path, 'RealWaste')\n",
        "    if os.path.isdir(realwaste_dir):\n",
        "        !mv {realwaste_dir}/* {dataset_path}\n",
        "        shutil.rmtree(realwaste_dir)  # Remove the now-empty RealWaste directory\n",
        "    git_dir = os.path.join(dataset_path, '.git')\n",
        "    if os.path.isdir(git_dir):\n",
        "        shutil.rmtree(git_dir)  # Remove the .git directory\n",
        "\n",
        "\n",
        "print(\"Dataset Path: \", dataset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57ec5d98-3f9d-4aa9-aabf-b2d12a54bdef",
      "metadata": {
        "tags": [],
        "id": "57ec5d98-3f9d-4aa9-aabf-b2d12a54bdef"
      },
      "source": [
        "## Datamodule\n",
        "\n",
        "Siehe: https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n",
        "\n",
        "Im Rahmen des Projekts RealWaste wurde eine spezielle Klasse, `ConfigurableDataModule`, entwickelt, um den Umgang mit Datensätzen für maschinelles Lernen zu vereinfachen und flexibler zu gestalten. Diese Klasse ist eine vereinfachte Anpassung der PyTorch Lightning DataModule-Klasse und ermöglicht es, verschiedene Modelle dynamisch mit unterschiedlichen Datentransformationen zu experimentieren. Ziel ist es, Kollegen, die möglicherweise nicht tief in die Materie des maschinellen Lernens eingetaucht sind, einen leicht zugänglichen Weg zu bieten, um mit Datensätzen zu arbeiten.\n",
        "\n",
        "#### Kernfunktionalitäten:\n",
        "\n",
        "- **Flexibilität bei Datentransformationen:** Durch die Übergabe eines `transform`-Objekts beim Initialisieren der Klasse kann der Benutzer spezifische Transformationen definieren, die auf die Bilddaten angewendet werden sollen. Dies ermöglicht eine einfache Anpassung der Vorverarbeitungsschritte für unterschiedliche Modelle oder Experimente.\n",
        "\n",
        "- **Automatische Aufteilung des Datensatzes:** Im `setup`-Schritt teilt die Klasse den Datensatz automatisch in Trainings- und Validierungsdatensätze auf, basierend auf einem standardmäßigen Verhältnis von 80% Training zu 20% Validierung. Diese Aufteilung hilft dabei, das Modell während des Trainings zu evaluieren und die Generalisierbarkeit zu überprüfen.\n",
        "\n",
        "- **Einfaches Laden der Daten:** Die `train_dataloader`- und `val_dataloader`-Methoden erstellen DataLoader für die Trainings- und Validierungsdatensätze, welche das Batching der Daten und optional das Durchmischen (nur Trainingsdatensatz) übernehmen. Die Batch-Größe ist dabei ein konfigurierbarer Parameter, der beim Initialisieren der Klasse festgelegt wird. Siehe https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
        "\n",
        "#### Anwendung:\n",
        "\n",
        "Um die `ConfigurableDataModule`-Klasse zu nutzen, müssen Benutzer lediglich den Pfad zum Datensatz (`data_dir`), die gewünschte Batch-Größe und das Transformationsschema als Parameter angeben. Nach der Initialisierung kann die Klasse mit PyTorch Lightning Trainern verwendet werden, um das Modelltraining und die Validierung zu vereinfachen.\n",
        "\n",
        "#### Beispiel:\n",
        "\n",
        "```python\n",
        "from torchvision import transforms as T\n",
        "transform = T.Compose([\n",
        "    T.Resize((256, 256)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "data_module = ConfigurableDataModule(data_dir='/path/to/dataset', batch_size=32, transform=transform)\n",
        "```\n",
        "\n",
        "Mit diesem Ansatz können Projektbeteiligte verschiedene Bildverarbeitungstechniken und Modellarchitekturen schnell evaluieren, ohne tief in die Komplexität der Datenvorbereitung eintauchen zu müssen. Das anpassen der Transforms wird für jedes Modell individuell neu notwendig sein, da wir beispeilsweise die Größe das Bildes für das jeweilige Modell anpassen müssen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7eec889-2c78-49c4-b501-d8cd5b026d67",
      "metadata": {
        "tags": [],
        "id": "f7eec889-2c78-49c4-b501-d8cd5b026d67"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import LightningDataModule\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import os\n",
        "\n",
        "class ConfigurableDataModule(LightningDataModule):\n",
        "    \"\"\"Class wraper für mit austauschbaren transforms\"\"\"\n",
        "    def __init__(self, data_dir: str, batch_size: int, transform):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Erstellen des Datensatzes als Instanz von ImageFolder\n",
        "        full_dataset = ImageFolder(root=self.data_dir, transform=self.transform)\n",
        "        # Setzen der Trainingsset/Validierungsset Größe\n",
        "        train_size = int(0.8 * len(full_dataset))\n",
        "        val_size = len(full_dataset) - train_size\n",
        "        # Zufälliges aufteilen in Training- und Validierungdatensatz\n",
        "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Setzen des Traindataloader\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # Setzen des Validation Dataloader\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=os.cpu_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d8108ed-e9c2-4b40-8f04-a8bc5e132d2e",
      "metadata": {
        "id": "1d8108ed-e9c2-4b40-8f04-a8bc5e132d2e"
      },
      "source": [
        "## Lighting Module Basis\n",
        "\n",
        "Der `BaseWasteClassifier` bildet die Grundlage für eine Reihe von Klassifizierungsmodellen im Projekt RealWaste, das sich mit der Erkennung und Klassifizierung von Abfallbildern beschäftigt. Diese Klasse erbt von PyTorch Lightning's `LightningModule` und bietet ein Grundgerüst, das für alle spezifischen Klassifizierungsmodelle innerhalb des Projekts angepasst werden kann. Ziel ist es, eine konsistente Struktur und gemeinsame Funktionalitäten für das Training, die Validierung und die Metrikbewertung bereitzustellen, um die Entwicklung und Evaluierung von Modellen zu vereinfachen.\n",
        "\n",
        "#### Kernfunktionalitäten:\n",
        "\n",
        "- **Modellstruktur:** Die Klasse definiert eine variable `model`, die in abgeleiteten Klassen mit spezifischen Modellarchitekturen (z.B. CNNs für Bildklassifizierung) gefüllt wird. Dies ermöglicht Flexibilität und Wiederverwendbarkeit des Codes.\n",
        "\n",
        "- **Metriken:** `BaseWasteClassifier` initialisiert standardisierte Metriken für Genauigkeit (Accuracy), Präzision (Precision) und Rückruf (Recall), die für Multiklassen-Klassifizierungsprobleme angepasst sind. Diese Metriken erleichtern die Leistungsbewertung über verschiedene Modelle hinweg.\n",
        "\n",
        "- **Datenfluss:** Die Methoden `forward`, `training_step`, und `validation_step` definieren den grundlegenden Datenfluss durch das Modell. Dabei ist `forward` für die Vorwärtspropagierung, `training_step` für die Berechnung des Verlusts und der Metriken während des Trainings und `validation_step` für die Auswertung während der Validierung zuständig.\n",
        "\n",
        "- **Optimierung:** Durch die Methode `configure_optimizers` wird standardmäßig ein SGD-Optimizer definiert. Diese Methode kann in abgeleiteten Klassen überschrieben werden, um spezifische Optimierungsstrategien zu implementieren.\n",
        "\n",
        "#### Anwendung:\n",
        "\n",
        "Um ein spezifisches Klassifizierungsmodell zu erstellen, sollten Entwickler eine neue Klasse definieren, die von `BaseWasteClassifier` erbt und die `model`-Variable mit einer geeigneten Modellarchitektur (z.B. ein bestimmtes neuronales Netzwerk) sowie die Methode `forward` zur Definition der Vorwärtspropagierung füllt. Dies ermöglicht eine strukturierte und einheitliche Herangehensweise an die Modellentwicklung.\n",
        "\n",
        "#### Beispiel:\n",
        "\n",
        "```python\n",
        "class SpecificWasteClassifier(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__(num_classes=num_classes)\n",
        "        self.model = ...  # Definiere hier die spezifische Modellarchitektur\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Implementiere die Vorwärtspropagierung\n",
        "        return self.model(x)\n",
        "```\n",
        "\n",
        "Durch diesen Ansatz können Entwickler im RealWaste-Projekt verschiedene Modelle schnell iterieren und evaluieren, wobei sie sich auf das wesentliche Design der Modellarchitektur konzentrieren können, ohne sich jedes Mal um die Implementierungsdetails von Training und Validierung kümmern zu müssen. Es ist wichtig zu betonen, dass `BaseWasteClassifier` speziell für das Projekt RealWaste entwickelt wurde, um eine konsistente und effiziente Entwicklungspraxis zu fördern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0e8276d-bcf3-4f07-9a2d-6cb9c9c33060",
      "metadata": {
        "tags": [],
        "id": "d0e8276d-bcf3-4f07-9a2d-6cb9c9c33060"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from torchvision.transforms.functional import to_pil_image, to_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa57aed-bda2-4e86-9105-0ce5af309539",
      "metadata": {
        "tags": [],
        "id": "0fa57aed-bda2-4e86-9105-0ce5af309539"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "import torchmetrics\n",
        "import torchvision\n",
        "import torchvision.utils as vutils\n",
        "import random\n",
        "\n",
        "class BaseWasteClassifier(pl.LightningModule):\n",
        "\n",
        "    CLASS_NAMES =  ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
        "\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.num_classes = num_classes\n",
        "        # Placeholder for the actual model, to be defined in subclasses\n",
        "        self.model = None\n",
        "\n",
        "        # Initialize metrics common to all models\n",
        "        self.accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes, average='macro')\n",
        "        self.precision = torchmetrics.Precision(task='multiclass', num_classes=num_classes, average='weighted')\n",
        "        self.recall = torchmetrics.Recall(task='multiclass', num_classes=num_classes, average='weighted')\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Subclasses should implement this method\n",
        "        raise NotImplementedError(\"This method should be overridden by subclasses.\")\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
        "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
        "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
        "        predictions = torch.argmax(logits, dim=1)  # Convert logits to predicted class indices\n",
        "\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_acc', acc, prog_bar=True)\n",
        "\n",
        "        if random.random() < 0.1:  # Log images randomly\n",
        "            self.log_images_with_labels(x, y, predictions, batch_idx)  # Pass predictions correctly\n",
        "\n",
        "\n",
        "    def log_images_with_labels(self, images, labels, predictions, batch_idx):\n",
        "        \"\"\"Log a batch of images with their actual and predicted labels to TensorBoard.\"\"\"\n",
        "        annotated_images = []\n",
        "\n",
        "        for i in range(images.size(0)):\n",
        "            img = images[i]\n",
        "            actual_label = labels[i].item()\n",
        "            predicted_label = predictions[i].item()\n",
        "\n",
        "            # Unnormalize the image for visualization\n",
        "            img = self.unnormalize(img)  # Make sure to call with self if it's an instance method\n",
        "\n",
        "            # Convert to PIL Image for easy manipulation\n",
        "            pil_img = to_pil_image(img)\n",
        "            draw = ImageDraw.Draw(pil_img)\n",
        "            annotation_text = f'Actual: {self.CLASS_NAMES[actual_label]},\\n Predicted: {self.CLASS_NAMES[predicted_label]}'\n",
        "            draw.text((10, 10), annotation_text, fill=\"white\")\n",
        "\n",
        "            # Convert back to tensor and add to list\n",
        "            annotated_img = to_tensor(pil_img)\n",
        "            annotated_images.append(annotated_img.unsqueeze(0))  # Add batch dimension\n",
        "\n",
        "        # Stack all annotated images into a single tensor for logging\n",
        "        annotated_images_tensor = torch.cat(annotated_images, dim=0)\n",
        "        img_grid = torchvision.utils.make_grid(annotated_images_tensor, nrow=4)\n",
        "\n",
        "        # Log the grid of annotated images\n",
        "        self.logger.experiment.add_image(f'Validation Images, Batch {batch_idx}', img_grid, self.current_epoch)\n",
        "\n",
        "\n",
        "    def unnormalize(self, image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n",
        "        \"\"\"Revert normalization of an image tensor.\"\"\"\n",
        "        image = image.clone()  # Clone the tensor to avoid in-place operations\n",
        "        for t, m, s in zip(image, mean, std):\n",
        "            t.mul_(s).add_(m)  # Multiply by std and add mean\n",
        "        return image\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # Subclasses can override this if needed\n",
        "        optimizer = torch.optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
        "        return optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2c29d7f-0523-4e38-acf5-87038964dd7f",
      "metadata": {
        "id": "e2c29d7f-0523-4e38-acf5-87038964dd7f"
      },
      "source": [
        "## Trainingsprozess Funktion\n",
        "\n",
        "Für das Projekt RealWaste wurde eine standardisierte Methode zur Durchführung des Trainingsprozesses von Modellen etabliert. Diese Methode, `train_model`, vereinfacht das Training von Klassifizierungsmodellen durch die Automatisierung gängiger Schritte und die Integration von Logging-Funktionalitäten. Ziel ist es, Entwicklern eine einfache und effiziente Möglichkeit zu bieten, verschiedene Modelle zu trainieren und deren Leistung zu überwachen.\n",
        "\n",
        "#### Kernfunktionalitäten:\n",
        "\n",
        "- **Trainingseinrichtung:** Die Funktion nimmt ein Modell und ein Datenmodul als Parameter entgegen und konfiguriert den Trainingsprozess. Das Datenmodul sollte eine Instanz der zuvor beschriebenen `ConfigurableDataModule`-Klasse oder einer ähnlichen Klasse sein, die die Daten für das Training und die Validierung bereitstellt.\n",
        "\n",
        "- **Logging:** Durch die Verwendung eines `TensorBoardLogger` wird ein Logging-Mechanismus eingerichtet, der es ermöglicht, Metriken und Trainingsfortschritte in TensorBoard zu verfolgen. Dies erleichtert die Analyse des Modellverhaltens über die Zeit und unterstützt die visuelle Auswertung der Modellleistung.\n",
        "\n",
        "- **Trainingskonfiguration:** Die Funktion erlaubt die Definition der maximalen Anzahl von Epochen durch den Parameter `max_epochs`. Dies gibt an, wie lange das Modell trainiert werden soll. Standardmäßig ist dieser Wert auf 5 gesetzt, kann jedoch für längere Trainingsläufe entsprechend angepasst werden.\n",
        "\n",
        "- **Flexibilität:** Durch den optionalen Parameter `logger_name` kann der Name des Log-Verzeichnisses angepasst werden, was eine organisierte Speicherung von Trainingslogs für verschiedene Modelle oder Trainingsläufe ermöglicht.\n",
        "\n",
        "#### Anwendung:\n",
        "\n",
        "Um ein Modell zu trainieren, erstellen Entwickler zunächst eine Instanz ihres Modells und des Datenmoduls und rufen dann `train_model` mit diesen Instanzen auf. Optional können sie die Anzahl der Trainingsepochen und den Namen des Log-Verzeichnisses anpassen.\n",
        "\n",
        "#### Beispiel:\n",
        "\n",
        "```python\n",
        "model = SpecificWasteClassifier(num_classes=9)  # Ein spezifisches Modell für das Projekt\n",
        "data_module = ConfigurableDataModule(data_dir='/path/to/dataset', batch_size=32, transform=transform)  # Das Datenmodul\n",
        "\n",
        "train_model(model, data_module, max_epochs=10, logger_name=\"waste_classifier_logs\")\n",
        "```\n",
        "\n",
        "Durch die Verwendung dieser Methode können Entwickler im RealWaste-Projekt den Trainingsprozess ihrer Modelle mit minimalen Aufwand steuern und überwachen, was eine schnelle Iteration und Optimierung der Modelle ermöglicht. Es ist wichtig zu betonen, dass diese Methode speziell für die Bedürfnisse des RealWaste-Projekts entwickelt wurde, um eine konsistente und effektive Trainingspraxis zu fördern."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53d961fc-7b52-4c68-b7e2-aa1bbd4b0c97",
      "metadata": {
        "tags": [],
        "id": "53d961fc-7b52-4c68-b7e2-aa1bbd4b0c97"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "def train_model(model, data_module, log_dir=\"tb_logs\", max_epochs=5, logger_name=\"model_logs\"):\n",
        "    # Starten das Trainingsprozesses\n",
        "    logger = TensorBoardLogger(log_dir, name=logger_name)\n",
        "    trainer = Trainer(max_epochs=max_epochs, logger=logger)\n",
        "    trainer.fit(model, datamodule=data_module)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3108bd9-de44-4470-895d-bb37ebcbb848",
      "metadata": {
        "id": "d3108bd9-de44-4470-895d-bb37ebcbb848"
      },
      "source": [
        "# InceptionWasteClassifier\n",
        "\n",
        "Der `InceptionWasteClassifier` ist eine spezialisierte Implementierung des `BaseWasteClassifier` für das Projekt RealWaste, der das Inception v3-Modell für die Klassifizierung von Abfallbildern nutzt. Diese Klasse erweitert das grundlegende Framework, das durch `BaseWasteClassifier` bereitgestellt wird, um die leistungsstarke Architektur des Inception-Modells zu integrieren und anzupassen. Ziel ist es, eine hochpräzise Bildklassifizierungslösung zu bieten, die auf den spezifischen Anforderungen des RealWaste-Projekts basiert.\n",
        "\n",
        "#### Kernfunktionalitäten:\n",
        "\n",
        "- **Integration von Inception v3:** Durch die Nutzung des vortrainierten Inception v3-Modells als Basisarchitektur ermöglicht `InceptionWasteClassifier` eine effektive Feature-Extraktion und Klassifizierung. Das Modell wird mit Standardgewichten initialisiert, was einen guten Ausgangspunkt für das Training bietet.\n",
        "\n",
        "- **Anpassung an die Zielklassen:** Die finale vollverbundene Schicht (`fc`) des Inception-Modells wird durch eine neue Schicht ersetzt, deren Ausgabegröße der Anzahl der Zielklassen im RealWaste-Projekt entspricht. Dies ist eine gängige Technik, um vortrainierte Modelle für neue Klassifizierungsaufgaben anzupassen.\n",
        "\n",
        "- **Unterstützung für Hilfsausgaben:** Im Trainingmodus liefert das Modell zusätzlich zu den Hauptlogits Hilfslogits (`aux_logits`), die für die Berechnung des Verlusts verwendet werden können, um die Konvergenz zu verbessern. Diese Dualität wird in der `forward`-Methode gehandhabt, indem je nach Modus entweder beide Outputs oder nur die Hauptlogits zurückgegeben werden.\n",
        "\n",
        "- **Spezifische Trainingslogik:** Die `training_step`-Methode ist so angepasst, dass sie sowohl mit den Haupt- als auch mit den Hilfslogits arbeiten kann, wobei der Hauptfokus auf den Hauptlogits liegt. Dies unterstützt eine effektive Rückpropagation und Leistungsoptimierung während des Trainings.\n",
        "\n",
        "#### Anwendung:\n",
        "\n",
        "Um den `InceptionWasteClassifier` zu verwenden, müssen Entwickler lediglich eine Instanz der Klasse erstellen und das Training mit einem geeigneten Datensatz beginnen. Dank der Erweiterung von `BaseWasteClassifier` erbt der `InceptionWasteClassifier` alle Trainings- und Validierungsmethoden, was eine nahtlose Integration in das Projekt RealWaste ermöglicht.\n",
        "\n",
        "#### Beispiel:\n",
        "\n",
        "```python\n",
        "# Instanziierung des InceptionWasteClassifier\n",
        "model = InceptionWasteClassifier(num_classes=9)  # Für 9 verschiedene Abfallklassen\n",
        "\n",
        "# Vorbereitung des Datenmoduls und Start des Trainingsprozesses\n",
        "data_module = ConfigurableDataModule(data_dir='/path/to/dataset', batch_size=32, transform=transform)\n",
        "train_model(model, data_module, max_epochs=10, logger_name=\"inception_waste_classifier_logs\")\n",
        "```\n",
        "\n",
        "Durch die Verwendung des `InceptionWasteClassifier` können Entwickler im RealWaste-Projekt von den fortschrittlichen Fähigkeiten des Inception v3-Modells profitieren, angepasst an die spezifischen Anforderungen der Abfallbildklassifizierung. Dieser Ansatz fördert nicht nur eine hohe Genauigkeit und Effizienz in der Modellleistung, sondern auch eine schnelle und effektive Entwicklung und Evaluierung von Modellen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e31eee-4420-4de8-8245-733b9a4c2d28",
      "metadata": {
        "tags": [],
        "id": "b7e31eee-4420-4de8-8245-733b9a4c2d28"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import inception_v3\n",
        "\n",
        "class InceptionWasteClassifier(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes=9):\n",
        "        super().__init__(num_classes)\n",
        "        self.model = inception_v3(aux_logits=True, weights=\"Inception_V3_Weights.DEFAULT\")\n",
        "        self.model.fc = torch.nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training:\n",
        "            outputs = self.model(x)\n",
        "            return outputs.logits, outputs.aux_logits\n",
        "        else:\n",
        "            return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        outputs = self(x)  # This could be either a tensor or a tuple of tensors\n",
        "        logits = outputs if isinstance(outputs, torch.Tensor) else outputs[0]  # Select logits\n",
        "        loss = torch.nn.functional.cross_entropy(logits, y)\n",
        "        acc = self.accuracy(torch.argmax(logits, dim=1), y)\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
        "        return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3651709-6127-4c90-b997-3e8683af1d39",
      "metadata": {
        "tags": [],
        "id": "e3651709-6127-4c90-b997-3e8683af1d39"
      },
      "source": [
        "## Datenvorbereitung für InceptionWasteClassifier\n",
        "\n",
        "Um den `InceptionWasteClassifier` im Projekt RealWaste effektiv zu nutzen, ist eine spezifische Datenvorbereitung erforderlich. Diese Vorbereitung umfasst die Anwendung einer Reihe von Transformationen auf die Bilddaten, um sie für das Inception v3-Modell geeignet zu machen. Der folgende Abschnitt beschreibt die notwendigen Schritte und Transformationen, die implementiert werden müssen, um die Bilddaten für das Training und die Validierung des `InceptionWasteClassifier` zu optimieren.\n",
        "\n",
        "#### Kerntransformationen:\n",
        "\n",
        "- **Bildgrößenanpassung und Zentrierter Zuschnitt:** Zunächst werden die Bilder auf eine Größe von 342x342 Pixeln skaliert und dann auf eine zentrierte Fläche von 299x299 Pixeln zugeschnitten. Diese Größenanpassung und der Zuschnitt sind spezifisch auf die Anforderungen des Inception v3-Modells abgestimmt, welches Eingaben in dieser Größe erwartet.\n",
        "\n",
        "- **Konvertierung zu einem Tensor:** Die transformierten Bilder werden in Tensoren umgewandelt, um sie für die Verarbeitung mit PyTorch kompatibel zu machen.\n",
        "\n",
        "- **Normalisierung:** Die Pixelwerte der Bilder werden normalisiert, indem ein Mittelwert von `[0.485, 0.456, 0.406]` und eine Standardabweichung von `[0.229, 0.224, 0.225]` angewendet werden. Diese Normalisierungswerte sind auf die Verteilung der Daten im Imagenet-Trainingssatz abgestimmt, auf dem das Inception v3-Modell ursprünglich trainiert wurde. Diese Schritte sind entscheidend, um eine konsistente und effektive Modellleistung zu gewährleisten.\n",
        "\n",
        "#### Anwendung der Transformationen:\n",
        "\n",
        "Die definierten Transformationen sollten auf alle Bilddaten angewendet werden, die für das Training und die Validierung des `InceptionWasteClassifier` verwendet werden. Dies wird erreicht, indem die Transformationen in das Datenmodul integriert werden, das die Daten für das Modell lädt und vorbereitet.\n",
        "\n",
        "#### Beispiel:\n",
        "\n",
        "```python\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Pfad zum Datensatz\n",
        "data_dir = '/path/to/dataset'\n",
        "\n",
        "# Erstellung des transformierten Datensatzes\n",
        "transformed_dataset = ImageFolder(root=data_dir, transform=transforms)\n",
        "\n",
        "# Laden des Datensatzes als DataLoader für das Training\n",
        "data_loader = DataLoader(transformed_dataset, batch_size=32, shuffle=True)\n",
        "```\n",
        "\n",
        "Durch die Anwendung dieser spezifischen Transformationen können Entwickler sicherstellen, dass die Bilddaten optimal für das Inception v3-Modell vorbereitet sind, wodurch die Genauigkeit und Effizienz des `InceptionWasteClassifier` im Projekt RealWaste maximiert wird. Dieser methodische Ansatz zur Datenvorbereitung ist ein wesentlicher Schritt, um die Leistungsfähigkeit des Modells voll auszuschöpfen und präzise Klassifizierungsergebnisse zu erzielen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc6d438a-cba6-4bab-847f-9e5575cdf6a0",
      "metadata": {
        "tags": [],
        "id": "dc6d438a-cba6-4bab-847f-9e5575cdf6a0"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "# Define the transformations as per Inception V3's requirements\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(342, interpolation=InterpolationMode.BILINEAR),\n",
        "    transforms.CenterCrop(299),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "model = InceptionWasteClassifier()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5f4acb7-fed6-4722-a266-723351d73924",
      "metadata": {
        "id": "d5f4acb7-fed6-4722-a266-723351d73924"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0f25ea-e3ad-477a-bd29-dc90c009a06e",
      "metadata": {
        "tags": [],
        "id": "da0f25ea-e3ad-477a-bd29-dc90c009a06e",
        "outputId": "b2d3896c-9fb6-4b00-d910-a1dce9510a4d"
      },
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Bitte den gewünschten Pfad für die Log Datein eingeben: /home/jovyan/logs\n"
          ]
        }
      ],
      "source": [
        "# Eigene Paket\n",
        "from utils.colab_helper import in_colab\n",
        "\n",
        "if in_colab():\n",
        "    # Load the TensorBoard notebook extension\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir tb_logs\n",
        "    log_dir = \"tb_logs\"\n",
        "\n",
        "else:\n",
        "    log_dir = input(\"Bitte den gewünschten Pfad für die Log Datein eingeben:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6710edc9-bc65-40db-8b89-b92c47e17692",
      "metadata": {
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "",
            "1a1f7bfffb4c4971bd611c0ee3d57c94"
          ]
        },
        "id": "6710edc9-bc65-40db-8b89-b92c47e17692",
        "outputId": "249a3990-2064-4d21-f867-be8f6e812177"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: /home/jovyan/logs/InceptionWaste\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type                | Params\n",
            "--------------------------------------------------\n",
            "0 | accuracy  | MulticlassAccuracy  | 0     \n",
            "1 | precision | MulticlassPrecision | 0     \n",
            "2 | recall    | MulticlassRecall    | 0     \n",
            "3 | model     | Inception3          | 25.1 M\n",
            "--------------------------------------------------\n",
            "25.1 M    Trainable params\n",
            "0         Non-trainable params\n",
            "25.1 M    Total params\n",
            "100.523   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a1f7bfffb4c4971bd611c0ee3d57c94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "batch_size = 32\n",
        "data_module = ConfigurableDataModule(dataset_path, batch_size, transform)\n",
        "\n",
        "train_model(model, data_module, log_dir=log_dir, max_epochs=1, logger_name=\"InceptionWaste\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf3a1de-4d93-45b9-8f37-43b625f91638",
      "metadata": {
        "id": "dcf3a1de-4d93-45b9-8f37-43b625f91638"
      },
      "source": [
        "# Vision Transformer Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d0b4804-02fd-4f20-9b0a-aee6032aa2a1",
      "metadata": {
        "tags": [],
        "id": "0d0b4804-02fd-4f20-9b0a-aee6032aa2a1"
      },
      "outputs": [],
      "source": [
        "# Eigene Paket\n",
        "from utils.colab_helper import in_colab\n",
        "\n",
        "if in_colab():\n",
        "    # Load the TensorBoard\n",
        "    %tensorboard --logdir tb_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70378b78-0ee0-4b1a-b979-38e6334200ed",
      "metadata": {
        "tags": [],
        "id": "70378b78-0ee0-4b1a-b979-38e6334200ed"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import vit_b_16  # Ensure this matches your torchvision version and model choice\n",
        "\n",
        "class ViTWasteClassifier(BaseWasteClassifier):\n",
        "    def __init__(self, num_classes: int):\n",
        "        super().__init__(num_classes)\n",
        "        self.model = vit_b_16(weights=\"ViT_B_16_Weights.DEFAULT\")\n",
        "        # Access the 'head' layer within 'heads' to replace it for the number of target classes\n",
        "        in_features = self.model.heads[0].in_features  # Assuming 'head' is the first layer in 'heads'\n",
        "        self.model.heads[0] = torch.nn.Linear(in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # For ViT, simply return the model's output\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ccbcff-fcd3-4097-b5bd-5bf0cd6c1649",
      "metadata": {
        "tags": [],
        "id": "e7ccbcff-fcd3-4097-b5bd-5bf0cd6c1649"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d8cdf7-fa8b-4549-804b-6cfa665bc631",
      "metadata": {
        "tags": [],
        "id": "84d8cdf7-fa8b-4549-804b-6cfa665bc631"
      },
      "outputs": [],
      "source": [
        "data_module = ConfigurableDataModule(data_dir=dataset_path, batch_size=32, transform=transform)\n",
        "vit_model = ViTWasteClassifier(num_classes=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fbd467f-ff87-45e4-968c-2e9621343777",
      "metadata": {
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "",
            "b11fe998e13d4bfe9216ea4ae7ba94a4"
          ]
        },
        "id": "2fbd467f-ff87-45e4-968c-2e9621343777",
        "outputId": "79ef2b67-1344-4a1d-9292-d219b7567ee9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA RTX A6000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "2024-02-12 01:47:09.321785: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-12 01:47:09.421343: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-12 01:47:09.833273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-02-12 01:47:09.833327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-02-12 01:47:09.833333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type                | Params\n",
            "--------------------------------------------------\n",
            "0 | accuracy  | MulticlassAccuracy  | 0     \n",
            "1 | precision | MulticlassPrecision | 0     \n",
            "2 | recall    | MulticlassRecall    | 0     \n",
            "3 | model     | VisionTransformer   | 85.8 M\n",
            "--------------------------------------------------\n",
            "85.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "85.8 M    Total params\n",
            "343.222   Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b11fe998e13d4bfe9216ea4ae7ba94a4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
          ]
        }
      ],
      "source": [
        "train_model(model=vit_model, data_module=data_module, log_dir=log_dir, max_epochs=5, logger_name=\"ViT\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}